# Linear Regression（向量形式）— 参数从“数”变成“向量”

## 1. 这一步到底升级了什么？

上一版是一维输入：
y = w x + b

现在变成多维输入：
y = w^T x + b

其中：
- x 是一个向量（特征）：[x1, x2, ..., xd]
- w 也是一个向量（参数）：[w1, w2, ..., wd]
- b 是偏置（一个数）

关键变化只有一句话：
> 参数从 2 个（w, b）变成 d+1 个（w 向量 + b）。

---

## 2. 预测（forward）在干什么？

对每个样本 i：
y_pred(i) = w^T x(i) + b

这里的 w^T x 就是点积：
- 把每个特征按权重加权求和

---

## 3. loss 是什么？

仍然是均方误差（MSE）：
loss = mean( (y_pred - y_true)^2 )

注意：
- loss 是一个标量
- loss 是关于参数 (w, b) 的函数

---

## 4. 训练在干什么？

训练 = 在参数空间里做梯度下降：

w <- w - lr * d(loss)/d(w)
b <- b - lr * d(loss)/d(b)

这里：
- d(loss)/d(w) 是一个向量（和 w 同维度）
- d(loss)/d(b) 是一个数

---

## 5. 本阶段封账标准

你能说清楚这三句话就算完成：

1) 预测：y_pred = X @ w + b
2) loss：MSE 是关于 w、b 的函数
3) 梯度下降：w、b 会被不断更新，让 loss 变小